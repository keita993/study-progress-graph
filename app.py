import pandas as pd
import matplotlib
matplotlib.use('Agg')  # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’æ˜ç¤ºçš„ã«è¨­å®š

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
matplotlib.rcParams['font.family'] = 'IPAGothic'  # Streamlit Cloudã§åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆ

import matplotlib.font_manager as fm
import os

# ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’å¼·åŒ–ã™ã‚‹é–¢æ•°
def setup_japanese_font():
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚©ãƒ³ãƒˆã‚’æ¢ã™
    system_fonts = []
    
    # Windowsã®å ´åˆ
    if os.name == 'nt':
        font_paths = [
            r'C:\Windows\Fonts\meiryo.ttc',
            r'C:\Windows\Fonts\msgothic.ttc',
            r'C:\Windows\Fonts\YuGothM.ttc'
        ]
        for path in font_paths:
            if os.path.exists(path):
                system_fonts.append(path)
    
    # macOSã®å ´åˆ
    elif os.name == 'posix' and os.uname().sysname == 'Darwin':
        font_paths = [
            '/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ã‚·ãƒƒã‚¯ W3.ttc',
            '/System/Library/Fonts/AppleGothic.ttf',
            '/Library/Fonts/Osaka.ttf'
        ]
        for path in font_paths:
            if os.path.exists(path):
                system_fonts.append(path)
    
    # Linuxã®å ´åˆ
    elif os.name == 'posix':
        font_paths = [
            '/usr/share/fonts/truetype/fonts-japanese-gothic.ttf',
            '/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc'
        ]
        for path in font_paths:
            if os.path.exists(path):
                system_fonts.append(path)
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã¯è¨­å®š
    if system_fonts:
        for font_path in system_fonts:
            try:
                fm.fontManager.addfont(font_path)
                matplotlib.rcParams['font.family'] = fm.FontProperties(fname=font_path).get_name()
                return True
            except:
                continue
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
    matplotlib.rcParams['font.family'] = 'sans-serif'
    matplotlib.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans', 'Liberation Sans', 'Bitstream Vera Sans', 'sans-serif']
    
    return False

# ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’é©ç”¨
setup_japanese_font()

# ã‚°ãƒ©ãƒ•æç”»æ™‚ã®ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’å¼·åŒ–
def create_figure(figsize=(10, 6)):
    fig = plt.figure(figsize=figsize)
    ax = fig.add_subplot(111)
    
    # ã‚°ãƒ©ãƒ•å†…ã®ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
    plt.rcParams['axes.unicode_minus'] = False  # ãƒã‚¤ãƒŠã‚¹è¨˜å·ã‚’æ­£ã—ãè¡¨ç¤º
    plt.rcParams['font.size'] = 12  # ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚º
    
    return fig, ax

import matplotlib.pyplot as plt
import streamlit as st
import os
import urllib.request
import re
import numpy as np
import subprocess
import sys

# scipyã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆéƒ¨åˆ†ã‚’ä¿®æ­£
try:
    from scipy import stats
except ImportError:
    st.error("scipyãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚requirements.txtã«'scipy'ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="å¿œç”¨æƒ…å ±æŠ€è¡“è€…è©¦é¨“ å­¦ç¿’åˆ†æ",
    page_icon="ğŸ“Š"
)

# ã‚«ã‚¹ã‚¿ãƒ CSSã‚’ä¿®æ­£ - ãƒœãƒ¼ãƒ€ãƒ¼ã‚’å‰Šé™¤
st.markdown("""
<style>
h1, h2, h3, h4, h5, h6 {
    border-bottom: none;
    width: auto;
    padding: 0;
    margin: 0;
    line-height: 1.2;
    display: block;
    position: static;
}

/* ç–‘ä¼¼è¦ç´ ã‚’å‰Šé™¤ */
h1::after, h2::after, h3::after, h4::after, h5::after, h6::after {
    content: none;
}

/* h1ã®ã¿ä½™ç™½ã‚’è¿½åŠ  */
h1 {
    margin-bottom: 15px;
}

/* Streamlitã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚¿ã‚¤ãƒ«ã‚’ä¸Šæ›¸ã */
.stMarkdown h1, .stMarkdown h2, .stMarkdown h3, .stMarkdown h4, .stMarkdown h5, .stMarkdown h6 {
    margin-top: 0.5em !important;
    margin-bottom: 0.3em !important;
}

/* Streamlitã®ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚³ãƒ³ãƒ†ãƒŠã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’èª¿æ•´ */
.stMarkdown {
    padding-top: 0 !important;
    padding-bottom: 0 !important;
}

/* ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³ç”¨ã®ã‚¹ã‚¿ã‚¤ãƒ« */
@media (max-width: 768px) {
    /* ã‚¹ãƒãƒ›è¡¨ç¤ºæ™‚ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºèª¿æ•´ */
    h1 {
        font-size: 1.5rem !important;
    }
    h2 {
        font-size: 1.3rem !important;
    }
    h3 {
        font-size: 1.1rem !important;
    }
    
    /* ã‚°ãƒ©ãƒ•ã®ã‚µã‚¤ã‚ºèª¿æ•´ */
    .stPlot {
        width: 100% !important;
        height: auto !important;
    }
    
    /* ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®è¡¨ç¤ºèª¿æ•´ */
    .dataframe {
        font-size: 0.8rem !important;
        width: 100% !important;
        overflow-x: auto !important;
    }
    
    /* ãƒœã‚¿ãƒ³ã®ã‚µã‚¤ã‚ºèª¿æ•´ */
    .stButton > button {
        width: 100% !important;
        padding: 0.5rem !important;
    }
    
    /* ãƒ¡ãƒˆãƒªãƒƒã‚¯ã®ã‚µã‚¤ã‚ºèª¿æ•´ */
    .stMetric {
        font-size: 0.9rem !important;
    }
    
    /* ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®èª¿æ•´ */
    .row-widget.stHorizontal {
        flex-direction: column !important;
    }
    
    /* ä½™ç™½ã®èª¿æ•´ */
    .block-container {
        padding-left: 1rem !important;
        padding-right: 1rem !important;
    }
}
</style>
""", unsafe_allow_html=True)

st.title("å¿œç”¨æƒ…å ±æŠ€è¡“è€…è©¦é¨“ å­¦ç¿’åˆ†æ")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])

if uploaded_file is not None:
    try:
        # ãƒã‚¤ãƒŠãƒªãƒ¢ãƒ¼ãƒ‰ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        file_content = uploaded_file.read()
        
        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ¤œå‡º
        try:
            import chardet
            result = chardet.detect(file_content)
            detected_encoding = result['encoding']
            
        except:
            detected_encoding = None
        
        # æ§˜ã€…ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦ã™
        encodings_to_try = ['utf-8-sig', 'utf-8', 'shift-jis', 'cp932', 'euc-jp']
        if detected_encoding and detected_encoding not in encodings_to_try:
            encodings_to_try.insert(0, detected_encoding)
        
        df = None
        error_messages = []
        
        for encoding in encodings_to_try:
            try:
                # StringIOã‚’ä½¿ç”¨ã—ã¦ãƒ¡ãƒ¢ãƒªä¸Šã§ãƒ‡ã‚³ãƒ¼ãƒ‰
                import io
                string_data = io.StringIO(file_content.decode(encoding))
                df = pd.read_csv(string_data)
                
                break
            except UnicodeDecodeError as e:
                error_messages.append(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° '{encoding}' ã§ã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—: {str(e)}")
                continue
            except Exception as e:
                error_messages.append(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° '{encoding}' ã§ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {str(e)}")
                continue
        
        if df is None:
            st.error("ã™ã¹ã¦ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            st.write("ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:")
            for msg in error_messages:
                st.write(f"- {msg}")
            
            # æœ€å¾Œã®æ‰‹æ®µ: ãƒã‚¤ãƒŠãƒªãƒ¢ãƒ¼ãƒ‰ã§ç›´æ¥èª­ã¿è¾¼ã¿
            try:
                import io
                uploaded_file.seek(0)
                df = pd.read_csv(uploaded_file, encoding='latin1', error_bad_lines=False)
                st.warning("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’'latin1'ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚æ–‡å­—åŒ–ã‘ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            except:
                st.stop()
        
        # ã‚«ãƒ©ãƒ åã‚’æ¤œå‡ºã—ã¦ä¿®æ­£ã™ã‚‹éƒ¨åˆ†ã‚’æ”¹å–„
        if df is not None:
            # æ–‡å­—åŒ–ã‘ã—ãŸã‚«ãƒ©ãƒ åã‚’ä¿®æ­£
            column_mapping = {}
            
            # ã‚«ãƒ©ãƒ ã®ä½ç½®ã«åŸºã¥ã„ã¦è‡ªå‹•æ¤œå‡º
            if len(df.columns) >= 6:
                # å…¸å‹çš„ãªCSVãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å ´åˆ
                column_positions = {
                    0: 'No.',
                    1: 'å­¦ç¿’æ—¥',
                    2: 'å‡ºé¡Œ',
                    3: 'åˆ†é‡',
                    4: 'è§£ç­”æ™‚é–“',
                    5: 'æ­£ç­”ç‡',
                    6: 'å›ç­”'
                }
                
                for i, col in enumerate(df.columns):
                    if i in column_positions:
                        column_mapping[col] = column_positions[i]
            
            # ä½ç½®ãƒ™ãƒ¼ã‚¹ã®ãƒãƒƒãƒ”ãƒ³ã‚°ãŒãªã„å ´åˆã¯å†…å®¹ãƒ™ãƒ¼ã‚¹ã§æ¤œå‡º
            if not column_mapping:
                for col in df.columns:
                    col_str = str(col)
                    col_bytes = col_str.encode('unicode_escape')
                    
                    # å­¦ç¿’æ—¥ã‚«ãƒ©ãƒ ã®æ¤œå‡º
                    if 'å­¦ç¿’' in col_str or 'æ—¥ä»˜' in col_str or 'æ—¥æ™‚' in col_str or (b'\\u' in col_bytes and (b'w' in col_bytes or b'K' in col_bytes)):
                        column_mapping[col] = 'å­¦ç¿’æ—¥'
                    # åˆ†é‡ã‚«ãƒ©ãƒ ã®æ¤œå‡º
                    elif 'åˆ†é‡' in col_str or 'ã‚«ãƒ†ã‚´ãƒª' in col_str or 'é …ç›®' in col_str or (len(col_str) <= 2 and b'\\u' in col_bytes):
                        column_mapping[col] = 'åˆ†é‡'
                    # æ­£ç­”ç‡ã‚«ãƒ©ãƒ ã®æ¤œå‡º
                    elif 'æ­£ç­”ç‡' in col_str or 'æ­£è§£ç‡' in col_str or 'å¾—ç‚¹ç‡' in col_str or any(c in col_str for c in ['ç‡', 'ï¼…', '%']):
                        column_mapping[col] = 'æ­£ç­”ç‡'
            
            # ã‚«ãƒ©ãƒ åã‚’ä¿®æ­£
            if column_mapping:
                df = df.rename(columns=column_mapping)
        
        # å¿…è¦ãªã‚«ãƒ©ãƒ ã‚’ç‰¹å®š
        date_col = 'å­¦ç¿’æ—¥' if 'å­¦ç¿’æ—¥' in df.columns else None
        category_col = 'åˆ†é‡' if 'åˆ†é‡' in df.columns else None
        score_col = 'æ­£ç­”ç‡' if 'æ­£ç­”ç‡' in df.columns else None
        
        # ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ä½ç½®ã§æ¨æ¸¬
        if date_col is None and len(df.columns) > 1:
            date_col = df.columns[1]  # é€šå¸¸2åˆ—ç›®ãŒæ—¥ä»˜
        
        if category_col is None and len(df.columns) > 3:
            category_col = df.columns[3]  # é€šå¸¸4åˆ—ç›®ãŒåˆ†é‡
        
        if score_col is None and len(df.columns) > 5:
            score_col = df.columns[5]  # é€šå¸¸6åˆ—ç›®ãŒæ­£ç­”ç‡
        
        # ãã‚Œã§ã‚‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼
        if date_col is None or category_col is None or score_col is None:
            st.error("å¿…è¦ãªã‚«ãƒ©ãƒ ã‚’è‡ªå‹•æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        
        # æ—¥ä»˜ã‚’æ—¥ä»˜å‹ã«å¤‰æ›
        try:
            df[date_col] = pd.to_datetime(df[date_col])
        except:
            st.error(f"æ—¥ä»˜ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚«ãƒ©ãƒ  '{date_col}' ãŒæ—¥ä»˜å½¢å¼ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        
        # æ­£ç­”ç‡ã‚’æ•°å€¤å‹ã«å¤‰æ›
        try:
            # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆè¡¨è¨˜ï¼ˆä¾‹: 80%ï¼‰ã®å ´åˆ
            if df[score_col].dtype == 'object':
                df[score_col] = df[score_col].astype(str).str.rstrip('%').astype(float) / 100
            
            # ã™ã§ã«å°æ•°ç‚¹è¡¨è¨˜ï¼ˆä¾‹: 0.8ï¼‰ã®å ´åˆ
            if df[score_col].max() > 1:
                df[score_col] = df[score_col] / 100
        except:
            st.error(f"æ­£ç­”ç‡ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚«ãƒ©ãƒ  '{score_col}' ãŒæ•°å€¤ã¾ãŸã¯ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆå½¢å¼ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        
        # åˆ†æå‡¦ç†
        st.header("æ¦‚è¦")
        overall_avg = df[score_col].mean()
        st.metric("å…¨ä½“ã®å¹³å‡æ­£ç­”ç‡", f"{overall_avg*100:.1f}%")

        # æ—¥ä»˜ã”ã¨ã®å¹³å‡æ­£ç­”ç‡ã‚’è¨ˆç®—
        daily_avg = df.groupby(date_col)[score_col].mean() * 100

        # ç§»å‹•å¹³å‡ã‚’è¨ˆç®—ï¼ˆ7æ—¥é–“ï¼‰
        rolling_avg = daily_avg.rolling(window=7, min_periods=1).mean()

        # æ—¥ä»˜ã”ã¨ã®å¹³å‡è§£ç­”æ™‚é–“ã‚’è¨ˆç®—ï¼ˆè§£ç­”æ™‚é–“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
        if 'å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰' in df.columns:
            daily_time_avg = df.groupby(date_col)['å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰'].mean()
            # ç§»å‹•å¹³å‡ã‚’è¨ˆç®—ï¼ˆ7æ—¥é–“ï¼‰
            time_rolling_avg = daily_time_avg.rolling(window=7, min_periods=1).mean()
        else:
            daily_time_avg = None
            time_rolling_avg = None

        # æ—¥ä»˜ã”ã¨ã®å¹³å‡æ­£ç­”ç‡ã‚°ãƒ©ãƒ•
        st.header("æ—¥ä»˜ã”ã¨ã®å¹³å‡æ­£ç­”ç‡")
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.plot(daily_avg.index, daily_avg.values, label='Daily Accuracy')
        ax.plot(rolling_avg.index, rolling_avg.values, label='7-day Moving Average', linewidth=2)
        ax.set_ylabel('Accuracy (%)')
        ax.set_xlabel('Study Date')
        ax.legend()
        ax.grid(True, alpha=0.3)
        plt.tight_layout()
        st.pyplot(fig)
        
        # æ—¥ä»˜ã”ã¨ã®å¹³å‡æ­£ç­”ç‡ï¼ˆè¡¨ï¼‰éƒ¨åˆ†ã‚‚ãã®ã¾ã¾
        st.header("æ—¥ä»˜ã”ã¨ã®å¹³å‡æ­£ç­”ç‡ï¼ˆè¡¨ï¼‰")
        # æ—¥ä»˜ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºç”¨ã«æ•´å½¢
        daily_data = pd.DataFrame({
            'æ—¥ä»˜': daily_avg.index,
            'å•é¡Œæ•°': df.groupby(date_col).size().values,
            'å¹³å‡æ­£ç­”ç‡': [f"{val:.1f}%" for val in daily_avg.values],
            '7æ—¥ç§»å‹•å¹³å‡': [f"{val:.1f}%" for val in rolling_avg.values]
        })
        # æ—¥ä»˜ã‚’è¦‹ã‚„ã™ã„å½¢å¼ã«å¤‰æ›
        daily_data['æ—¥ä»˜'] = daily_data['æ—¥ä»˜'].dt.strftime('%Y-%m-%d')
        # æœ€æ–°ã®æ—¥ä»˜ãŒä¸Šã«æ¥ã‚‹ã‚ˆã†ã«ä¸¦ã¹æ›¿ãˆ
        daily_data = daily_data.sort_values('æ—¥ä»˜', ascending=False)
        # è¡¨ã‚’è¡¨ç¤º
        st.dataframe(daily_data)

        # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
        csv = daily_data.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="æ—¥ä»˜ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name='daily_accuracy.csv',
            mime='text/csv',
        )
        
        # è§£ç­”æ™‚é–“ã®åˆ†æéƒ¨åˆ†ã‚’ç§»å‹•ã™ã‚‹
        # ã€Œæ—¥ä»˜ã”ã¨ã®å¹³å‡æ­£ç­”ç‡ï¼ˆè¡¨ï¼‰ã€ã®å¾Œã«ç§»å‹•ã—ã€ã€Œåˆ†é‡ã”ã¨ã®å¹³å‡æ­£ç­”ç‡ã‚°ãƒ©ãƒ•ã€ã®å‰ã«é…ç½®

        # è§£ç­”æ™‚é–“ã‚«ãƒ©ãƒ ã‚’æ‰‹å‹•ã§æŒ‡å®šã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        st.header("è§£ç­”æ™‚é–“ã®åˆ†æ")
        use_auto_detection = st.checkbox("è§£ç­”æ™‚é–“ã‚«ãƒ©ãƒ ã‚’è‡ªå‹•æ¤œå‡ºã™ã‚‹", value=True)

        # å›ç­”æ™‚é–“ã®ã‚«ãƒ©ãƒ ã‚’ç‰¹å®š - æ”¹è‰¯ç‰ˆ
        time_col = None
        if use_auto_detection:
            # å„ªå…ˆåº¦ã®é«˜ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰æ¤œç´¢
            priority_keywords = ['è§£ç­”æ™‚é–“', 'å›ç­”æ™‚é–“', 'æ™‚é–“']
            for keyword in priority_keywords:
                for col in df.columns:
                    if keyword in str(col):
                        time_col = col
                    break
                if time_col:
                    break
            
            # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ã‚ˆã‚Šåºƒã„ç¯„å›²ã§æ¤œç´¢ï¼ˆãŸã ã—ã€Œåˆ†é‡ã€ã¯é™¤å¤–ï¼‰
            if time_col is None:
                for col in df.columns:
                    col_str = str(col).lower()
                    if ('åˆ†' in col_str or 'time' in col_str) and 'åˆ†é‡' not in col_str:
                        time_col = col
                        break
            
            # å›ç­”æ™‚é–“ã®ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ä½ç½®ã§æ¨æ¸¬
            if time_col is None and len(df.columns) > 4:
                time_col = df.columns[4]  # é€šå¸¸5åˆ—ç›®ãŒå›ç­”æ™‚é–“
        else:
            time_col = st.selectbox("è§£ç­”æ™‚é–“ã‚«ãƒ©ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„", df.columns.tolist())

        if time_col is not None:
            try:
                # è§£ç­”æ™‚é–“ã‚’åˆ†å˜ä½ã§å‡¦ç†
                
                # ã€Œã€œåˆ†ã€å½¢å¼ã‹ã‚‰æ•°å€¤ã‚’æŠ½å‡º
                if df[time_col].dtype == 'object':
                    # æ­£è¦è¡¨ç¾ã§æ•°å€¤éƒ¨åˆ†ã‚’æŠ½å‡º
                    df['å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰'] = df[time_col].astype(str).str.extract(r'(\d+\.?\d*)')[0].astype(float)
                else:
                    # æ•°å€¤å‹ã®å ´åˆã¯ãã®ã¾ã¾ä½¿ç”¨
                    df['å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰'] = df[time_col]
                
                # NaNå€¤ã‚’0ã«ç½®ãæ›ãˆ
                nan_count = df['å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰'].isna().sum()
                if nan_count > 0:
                    st.warning(f"{nan_count}å€‹ã®NaNå€¤ã‚’0ã«ç½®ãæ›ãˆã¾ã—ãŸ")
                    df['å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰'] = df['å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰'].fillna(0)
                
                # ç•°å¸¸å€¤ã®å‡¦ç†
                max_time_limit = st.slider("è§£ç­”æ™‚é–“ã®ä¸Šé™ï¼ˆåˆ†ï¼‰", min_value=1, max_value=120, value=30, step=1)
                outliers_count = (df['å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰'] > max_time_limit).sum()

                if outliers_count > 0:
                    # ç•°å¸¸å€¤ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿å­˜
                    df_with_outliers = df.copy()
                    
                    # ç•°å¸¸å€¤ã‚’é™¤å¤–
                    df_filtered = df[df['å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰'] <= max_time_limit].copy()
                    
                    st.warning(f"{outliers_count}å€‹ã®ç•°å¸¸å€¤ï¼ˆ{max_time_limit}åˆ†è¶…ï¼‰ã‚’é™¤å¤–ã—ã¾ã—ãŸ")
                    
                    # é™¤å¤–å‰å¾Œã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
                    col1, col2 = st.columns(2)
                    with col1:
                        st.subheader("é™¤å¤–å‰ã®çµ±è¨ˆ")
                        st.metric("ãƒ‡ãƒ¼ã‚¿æ•°", f"{len(df_with_outliers)}å€‹")
                        st.metric("å¹³å‡è§£ç­”æ™‚é–“", f"{df_with_outliers['å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰'].mean():.1f}åˆ†")
                        st.metric("æœ€å¤§è§£ç­”æ™‚é–“", f"{df_with_outliers['å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰'].max():.1f}åˆ†")
                    
                    with col2:
                        st.subheader("é™¤å¤–å¾Œã®çµ±è¨ˆ")
                        st.metric("ãƒ‡ãƒ¼ã‚¿æ•°", f"{len(df_filtered)}å€‹")
                        st.metric("å¹³å‡è§£ç­”æ™‚é–“", f"{df_filtered['å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰'].mean():.1f}åˆ†")
                        st.metric("æœ€å¤§è§£ç­”æ™‚é–“", f"{df_filtered['å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰'].max():.1f}åˆ†")
                    
                    # é™¤å¤–ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                    if st.checkbox("é™¤å¤–ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º"):
                        excluded_data = df_with_outliers[df_with_outliers['å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰'] > max_time_limit]
                        st.dataframe(excluded_data)
                    
                    # ä»¥é™ã®åˆ†æã«ã¯é™¤å¤–å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
                    df = df_filtered
                else:
                    st.success(f"ç•°å¸¸å€¤ï¼ˆ{max_time_limit}åˆ†è¶…ï¼‰ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                
                # æ—¥ä»˜ã”ã¨ã®å¹³å‡å›ç­”æ™‚é–“
                daily_time_avg = df.groupby(date_col)['å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰'].mean()
                
                # ç§»å‹•å¹³å‡ã‚’è¨ˆç®—ï¼ˆ7æ—¥é–“ï¼‰
                time_rolling_avg = daily_time_avg.rolling(window=7, min_periods=1).mean()
                
                # æ—¥ä»˜ã”ã¨ã®å¹³å‡å›ç­”æ™‚é–“ã‚°ãƒ©ãƒ•
                st.subheader("æ—¥ä»˜ã”ã¨ã®å¹³å‡è§£ç­”æ™‚é–“")
                fig, ax = plt.subplots(figsize=(10, 6))
                ax.plot(daily_time_avg.index, daily_time_avg.values, label='Daily Average Time')
                ax.plot(time_rolling_avg.index, time_rolling_avg.values, label='7-day Moving Average', linewidth=2)
                ax.set_ylabel('Response Time (minutes)')
                ax.set_xlabel('Study Date')
                ax.legend()
                ax.grid(True, alpha=0.3)
                plt.tight_layout()
                st.pyplot(fig)
                
                # åˆ†é‡ã”ã¨ã®å¹³å‡å›ç­”æ™‚é–“
                category_time_avg = df.groupby(category_col)['å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰'].mean().sort_values(ascending=False)
                
                # åˆ†é‡ã”ã¨ã®å¹³å‡å›ç­”æ™‚é–“ã‚’è¡¨å½¢å¼ã§è¡¨ç¤º
                st.subheader("åˆ†é‡ã”ã¨ã®å¹³å‡è§£ç­”æ™‚é–“")
                time_stats_df = pd.DataFrame({
                    'åˆ†é‡': category_time_avg.index,
                    'å¹³å‡è§£ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰': [f"{val:.1f}" for val in category_time_avg.values]
                })
                st.dataframe(time_stats_df)
                
                # å›ç­”æ™‚é–“ã®çµ±è¨ˆæƒ…å ±
                st.subheader("è§£ç­”æ™‚é–“ã®çµ±è¨ˆæƒ…å ±")
                col1, col2, col3 = st.columns(3)
                
                # å®Ÿéš›ã®å€¤ã‚’ä½¿ç”¨
                mean_time = df['å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰'].mean()
                min_time = df['å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰'].min()
                max_time = df['å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰'].max()
                
                with col1:
                    st.metric("å¹³å‡è§£ç­”æ™‚é–“", f"{mean_time:.1f}åˆ†")
                with col2:
                    st.metric("æœ€çŸ­è§£ç­”æ™‚é–“", f"{min_time:.1f}åˆ†")
                with col3:
                    st.metric("æœ€é•·è§£ç­”æ™‚é–“", f"{max_time:.1f}åˆ†")
                
                # è§£ç­”æ™‚é–“ã®åˆ†å¸ƒ
                st.subheader("è§£ç­”æ™‚é–“ã®åˆ†å¸ƒ")
                fig, ax = plt.subplots(figsize=(10, 6))
                ax.hist(df['å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰'], bins=20, alpha=0.7)
                ax.set_xlabel('Response Time (minutes)')
                ax.set_ylabel('Frequency')
                ax.grid(True, alpha=0.3)
                plt.tight_layout()
                st.pyplot(fig)
                
            except Exception as e:
                st.error(f"å›ç­”æ™‚é–“ã®åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                st.write("ã‚¨ãƒ©ãƒ¼ã®è©³ç´°:", e)
        else:
            st.info("è§£ç­”æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        
        # åˆ†é‡ã”ã¨ã®åˆ†æéƒ¨åˆ†ã‚’ä¿®æ­£
        st.header("åˆ†é‡ã”ã¨ã®åˆ†æ")

        # åˆ†é‡ã”ã¨ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºï¼ˆæ­£ç­”ç‡ãŒé«˜ã„é †ã«ä¸¦ã³æ›¿ãˆï¼‰
        category_count = df.groupby(category_col).size()
        category_avg_sorted = df.groupby(category_col)[score_col].mean().sort_values(ascending=False)
        category_stats = pd.DataFrame({
            'åˆ†é‡': category_avg_sorted.index,
            'å•é¡Œæ•°': [category_count[cat] for cat in category_avg_sorted.index],
            'æ­£ç­”ç‡': [f"{val:.1f}%" for val in category_avg_sorted.values]
        })

        # è¡¨ã‚’è¡¨ç¤º
        st.dataframe(category_stats)

        # å­¦ç¿’ã®é€²æ—çŠ¶æ³
        st.header("å­¦ç¿’ã®é€²æ—çŠ¶æ³")
        total_questions = len(df)
        study_days = len(df[date_col].unique())
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ç·å•é¡Œæ•°", f"{total_questions}å•")
        with col2:
            st.metric("å­¦ç¿’æ—¥æ•°", f"{study_days}æ—¥")
        with col3:
            st.metric("1æ—¥å¹³å‡å•é¡Œæ•°", f"{total_questions/study_days:.1f}å•")
        
        # åˆ†é‡ã®æ–‡å­—åŒ–ã‘ã‚’ä¿®æ­£ã™ã‚‹éƒ¨åˆ†ã‚’è¿½åŠ 
        if category_col in df.columns:
            # åˆ†é‡åã«æ–‡å­—åŒ–ã‘ãŒã‚ã‚‹å ´åˆã¯ä¿®æ­£
            unique_categories = df[category_col].unique()
            category_mapping = {}
            
            for cat in unique_categories:
                cat_str = str(cat)
                # æ–‡å­—åŒ–ã‘ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹å ´åˆ
                if '\\u' in repr(cat_str) or len(cat_str) <= 2:
                    # æ—¢çŸ¥ã®åˆ†é‡åã¨ç…§åˆ
                    known_categories = {
                        'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£': ['ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£', 'ã‚»ã‚­ãƒ¥', 'ã‚»'],
                        'ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£': ['ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£', 'ã‚¢ãƒ¼ã‚­', 'ã‚¢'],
                        'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ': ['ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ', 'ãƒ—ãƒ­ãƒãƒ', 'ãƒ—'],
                        'ã‚µãƒ¼ãƒ“ã‚¹ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ': ['ã‚µãƒ¼ãƒ“ã‚¹ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ', 'ã‚µãƒ¼ãƒ“ã‚¹', 'ã‚µ'],
                        'ã‚·ã‚¹ãƒ†ãƒ æˆ¦ç•¥': ['ã‚·ã‚¹ãƒ†ãƒ æˆ¦ç•¥', 'æˆ¦ç•¥', 'æˆ¦'],
                        'çµŒå–¶æˆ¦ç•¥': ['çµŒå–¶æˆ¦ç•¥', 'çµŒå–¶', 'çµŒ'],
                        'ã‚·ã‚¹ãƒ†ãƒ é–‹ç™º': ['ã‚·ã‚¹ãƒ†ãƒ é–‹ç™º', 'é–‹ç™º', 'é–‹'],
                        'çµ„è¾¼ã‚·ã‚¹ãƒ†ãƒ é–‹ç™º': ['çµ„è¾¼ã‚·ã‚¹ãƒ†ãƒ é–‹ç™º', 'çµ„è¾¼', 'çµ„'],
                        'ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹': ['ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹', 'DB', 'ãƒ‡'],
                        'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯': ['ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯', 'NW', 'ãƒ'],
                        'ã‚·ã‚¹ãƒ†ãƒ ç›£æŸ»': ['ã‚·ã‚¹ãƒ†ãƒ ç›£æŸ»', 'ç›£æŸ»', 'ç›£']
                    }
                    
                    # æ–‡å­—åˆ—ã®é¡ä¼¼åº¦ã§æœ€ã‚‚è¿‘ã„åˆ†é‡ã‚’è¦‹ã¤ã‘ã‚‹
                    for known_cat, aliases in known_categories.items():
                        for alias in aliases:
                            if alias in cat_str or cat_str in alias:
                                category_mapping[cat] = known_cat
                                break
            
            # ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’é©ç”¨
            if category_mapping:
                df[category_col] = df[category_col].map(lambda x: category_mapping.get(x, x))
        
        # AIåˆ†æã‚³ãƒ¡ãƒ³ãƒˆæ©Ÿèƒ½
        def generate_ai_analysis(df, score_col, date_col, category_col, time_col):
            """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸAIåˆ†æã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
            comments = []
            
            # å…¨ä½“ã®å‚¾å‘åˆ†æ
            overall_avg = df[score_col].mean() * 100
            if overall_avg >= 80:
                comments.append(f"å…¨ä½“ã®å¹³å‡æ­£ç­”ç‡ã¯{overall_avg:.1f}%ã§éå¸¸ã«è‰¯å¥½ã§ã™ã€‚å¿œç”¨æƒ…å ±æŠ€è¡“è€…è©¦é¨“ã«å¿…è¦ãªçŸ¥è­˜ã‚’ã—ã£ã‹ã‚Šèº«ã«ã¤ã‘ã¦ã„ã¾ã™ã€‚")
            elif overall_avg >= 60:
                comments.append(f"å…¨ä½“ã®å¹³å‡æ­£ç­”ç‡ã¯{overall_avg:.1f}%ã§è‰¯å¥½ã§ã™ã€‚ã•ã‚‰ã«å¾—ç‚¹ã‚’ä¼¸ã°ã™ãŸã‚ã«è‹¦æ‰‹åˆ†é‡ã‚’é‡ç‚¹çš„ã«å­¦ç¿’ã—ã¾ã—ã‚‡ã†ã€‚")
            else:
                comments.append(f"å…¨ä½“ã®å¹³å‡æ­£ç­”ç‡ã¯{overall_avg:.1f}%ã§ã™ã€‚åŸºç¤çš„ãªéƒ¨åˆ†ã‹ã‚‰å¾©ç¿’ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")
            
            # æœ€è¿‘ã®å‚¾å‘åˆ†æ
            if len(df) >= 10:
                recent_df = df.sort_values(date_col, ascending=False).head(10)
                recent_avg = recent_df[score_col].mean() * 100
                overall_avg = df[score_col].mean() * 100
                
                if recent_avg > overall_avg + 5:
                    comments.append(f"æœ€è¿‘10å•ã®å¹³å‡æ­£ç­”ç‡ã¯{recent_avg:.1f}%ã§ã€å…¨ä½“å¹³å‡ã‚ˆã‚Š{recent_avg-overall_avg:.1f}%é«˜ããªã£ã¦ã„ã¾ã™ã€‚å­¦ç¿’ã®æˆæœãŒå‡ºã¦ã„ã¾ã™ï¼")
                elif recent_avg < overall_avg - 5:
                    comments.append(f"æœ€è¿‘10å•ã®å¹³å‡æ­£ç­”ç‡ã¯{recent_avg:.1f}%ã§ã€å…¨ä½“å¹³å‡ã‚ˆã‚Š{overall_avg-recent_avg:.1f}%ä½ããªã£ã¦ã„ã¾ã™ã€‚ç–²ã‚ŒãŒå‡ºã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ä¼‘æ¯ã‚‚å¤§åˆ‡ã«ã—ã¾ã—ã‚‡ã†ã€‚")
            
            # è‹¦æ‰‹åˆ†é‡ã®åˆ†æ
            category_avg = df.groupby(category_col)[score_col].mean() * 100
            worst_categories = category_avg.sort_values().head(3)
            if len(worst_categories) > 0:
                worst_cat_names = ", ".join([f"{cat}({avg:.1f}%)" for cat, avg in worst_categories.items()])
                comments.append(f"è‹¦æ‰‹ãªåˆ†é‡ã¯ {worst_cat_names} ã§ã™ã€‚ã“ã‚Œã‚‰ã®åˆ†é‡ã‚’é‡ç‚¹çš„ã«å­¦ç¿’ã™ã‚‹ã“ã¨ã§å…¨ä½“ã®æ­£ç­”ç‡å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™ã€‚")
            
            # å¾—æ„åˆ†é‡ã®åˆ†æ
            best_categories = category_avg.sort_values(ascending=False).head(3)
            if len(best_categories) > 0:
                best_cat_names = ", ".join([f"{cat}({avg:.1f}%)" for cat, avg in best_categories.items()])
                comments.append(f"å¾—æ„ãªåˆ†é‡ã¯ {best_cat_names} ã§ã™ã€‚ã“ã‚Œã‚‰ã®åˆ†é‡ã®çŸ¥è­˜ã‚’æ´»ã‹ã—ã¦é–¢é€£åˆ†é‡ã®å­¦ç¿’ã‚‚é€²ã‚ã¾ã—ã‚‡ã†ã€‚")
            
            # è§£ç­”æ™‚é–“ã®åˆ†æ
            if 'time_col' in locals() and 'å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰' in df.columns:
                avg_time = df['å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰'].mean()
                if avg_time > 30:
                    comments.append(f"å¹³å‡è§£ç­”æ™‚é–“ã¯{avg_time:.1f}åˆ†ã§ã™ã€‚è§£ç­”ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚’ä¸Šã’ã‚‹ãŸã‚ã«ã€åŸºæœ¬çš„ãªçŸ¥è­˜ã®å®šç€ã‚’å›³ã‚Šã¾ã—ã‚‡ã†ã€‚")
                elif avg_time < 10:
                    comments.append(f"å¹³å‡è§£ç­”æ™‚é–“ã¯{avg_time:.1f}åˆ†ã¨é€Ÿã„ã§ã™ã€‚è§£ç­”ã®æ­£ç¢ºæ€§ã‚‚ç¢ºèªã—ãªãŒã‚‰é€²ã‚ã¾ã—ã‚‡ã†ã€‚")
            
            # å­¦ç¿’ãƒšãƒ¼ã‚¹ã®åˆ†æ
            study_days = len(df[date_col].unique())
            total_questions = len(df)
            if study_days > 0:
                questions_per_day = total_questions / study_days
                if questions_per_day >= 10:
                    comments.append(f"1æ—¥å¹³å‡{questions_per_day:.1f}å•ã¨è‰¯ã„ãƒšãƒ¼ã‚¹ã§å­¦ç¿’ã‚’ç¶šã‘ã¦ã„ã¾ã™ã€‚ã“ã®ãƒšãƒ¼ã‚¹ã‚’ç¶­æŒã—ã¾ã—ã‚‡ã†ã€‚")
                elif questions_per_day < 5:
                    comments.append(f"1æ—¥å¹³å‡{questions_per_day:.1f}å•ã§ã™ã€‚å¯èƒ½ã§ã‚ã‚Œã°å­¦ç¿’é‡ã‚’å¢—ã‚„ã™ã“ã¨ã‚’æ¤œè¨ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
            
            # å­¦ç¿’ã®ç¶™ç¶šæ€§åˆ†æ
            if study_days > 1:
                date_diff = (df[date_col].max() - df[date_col].min()).days
                if date_diff > 0:
                    continuity = study_days / date_diff
                    if continuity >= 0.7:
                        comments.append("å­¦ç¿’ã®ç¶™ç¶šæ€§ãŒé«˜ãã€ç´ æ™´ã‚‰ã—ã„ã§ã™ã€‚ç¶™ç¶šã¯åŠ›ãªã‚Šã§ã™ï¼")
                    elif continuity <= 0.3:
                        comments.append("å­¦ç¿’ã®é–“éš”ãŒç©ºã„ã¦ã„ã¾ã™ã€‚å®šæœŸçš„ãªå­¦ç¿’ç¿’æ…£ã‚’ä½œã‚‹ã“ã¨ã§åŠ¹æœãŒé«˜ã¾ã‚Šã¾ã™ã€‚")
            
            return comments

        # AIåˆ†æã‚³ãƒ¡ãƒ³ãƒˆéƒ¨åˆ†ã‚’ä¿®æ­£
        st.header("AIåˆ†æã‚³ãƒ¡ãƒ³ãƒˆ")

        # ãƒœã‚¿ãƒ³ã‚’å‰Šé™¤ã—ã€è‡ªå‹•çš„ã«åˆ†æã‚’å®Ÿè¡Œ
        with st.spinner("åˆ†æä¸­..."):
            ai_comments = generate_ai_analysis(df, score_col, date_col, category_col, time_col)
            
            for i, comment in enumerate(ai_comments):
                st.info(comment)
            
            # ç·åˆã‚¢ãƒ‰ãƒã‚¤ã‚¹
            st.subheader("ç·åˆã‚¢ãƒ‰ãƒã‚¤ã‚¹")
            overall_avg = df[score_col].mean() * 100
            
            if overall_avg >= 80:
                st.success("ç¾åœ¨ã®å­¦ç¿’çŠ¶æ³ã¯éå¸¸ã«è‰¯å¥½ã§ã™ã€‚ã“ã®ã¾ã¾æ¨¡æ“¬è©¦é¨“ãªã©ã§å®Ÿè·µçš„ãªå•é¡Œã«ã‚‚å–ã‚Šçµ„ã‚“ã§ã¿ã¾ã—ã‚‡ã†ã€‚")
            elif overall_avg >= 60:
                st.warning("åŸºç¤ã¯ã§ãã¦ã„ã¾ã™ãŒã€ã¾ã æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™ã€‚è‹¦æ‰‹åˆ†é‡ã‚’ä¸­å¿ƒã«å­¦ç¿’ã‚’ç¶šã‘ã¾ã—ã‚‡ã†ã€‚")
            else:
                st.error("åŸºç¤çš„ãªéƒ¨åˆ†ã‹ã‚‰è¦‹ç›´ã™å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆã‚’å†åº¦ç¢ºèªã—ã€åŸºæœ¬æ¦‚å¿µã®ç†è§£ã‚’æ·±ã‚ã¾ã—ã‚‡ã†ã€‚")

        # å­¦ç¿’é€²æ—ã®ç·åˆè©•ä¾¡ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æœ€å¾Œã«è¿½åŠ 
        st.header("å­¦ç¿’é€²æ—ã®ç·åˆè©•ä¾¡")

        try:
            # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã®ãŸã‚ã®æº–å‚™
            # æ¡ä»¶ãƒã‚§ãƒƒã‚¯ã‚’ä¿®æ­£ - è§£ç­”æ™‚é–“ãƒ‡ãƒ¼ã‚¿ã®æœ‰ç„¡ã‚’ç¢ºèª
            has_time_data = 'å›ç­”æ™‚é–“ï¼ˆåˆ†ï¼‰' in df.columns and daily_time_avg is not None and len(daily_time_avg) > 0
            
            # ãƒ‡ãƒ¼ã‚¿ãŒååˆ†ã«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if len(daily_avg) >= 3:  # æœ€ä½3æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°åˆ†æå¯èƒ½
                # ç§»å‹•å¹³å‡ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
                recent_rolling_avg = rolling_avg.tail(min(7, len(rolling_avg)))  # åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã‚’æœ€å¤§7æ—¥åˆ†ä½¿ç”¨
                
                # æ­£ç­”ç‡ã®ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
                x_acc = range(len(recent_rolling_avg))
                slope_acc, _, _, _, _ = stats.linregress(x_acc, recent_rolling_avg.values)
                
                # è©•ä¾¡ã‚’è¡¨ç¤º
                col1, col2 = st.columns(2)
                
                with col1:
                    if slope_acc > 0.5:
                        st.success("ğŸ“ˆ æ­£ç­”ç‡ãŒä¸Šæ˜‡å‚¾å‘ã«ã‚ã‚Šã¾ã™ï¼")
                    elif slope_acc < -0.5:
                        st.error("ğŸ“‰ æ­£ç­”ç‡ãŒä¸‹é™å‚¾å‘ã«ã‚ã‚Šã¾ã™")
                    else:
                        st.info("ğŸ“Š æ­£ç­”ç‡ã¯å®‰å®šã—ã¦ã„ã¾ã™")
                
                # è§£ç­”æ™‚é–“ã®ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æï¼ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
                if has_time_data:
                    # è§£ç­”æ™‚é–“ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                    recent_time_rolling_avg = time_rolling_avg.tail(min(7, len(time_rolling_avg)))
                    
                    # è§£ç­”æ™‚é–“ã®ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æï¼ˆååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
                    if len(recent_time_rolling_avg) >= 3:
                        with col2:
                            x_time = range(len(recent_time_rolling_avg))
                            slope_time, _, _, _, _ = stats.linregress(x_time, recent_time_rolling_avg.values)
                            
                            if slope_time < -0.2:
                                st.success("â±ï¸ è§£ç­”æ™‚é–“ãŒçŸ­ç¸®å‚¾å‘ã«ã‚ã‚Šã¾ã™ï¼")
                            elif slope_time > 0.2:
                                st.warning("â±ï¸ è§£ç­”æ™‚é–“ãŒå¢—åŠ å‚¾å‘ã«ã‚ã‚Šã¾ã™")
                            else:
                                st.info("â±ï¸ è§£ç­”æ™‚é–“ã¯å®‰å®šã—ã¦ã„ã¾ã™")
                        
                        # ç·åˆè©•ä¾¡ï¼ˆè§£ç­”æ™‚é–“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
                        if slope_acc > 0.5 and slope_time < -0.2:
                            st.success("ğŸ‘ æ­£ç­”ç‡ãŒä¸Šæ˜‡ã—ã€è§£ç­”æ™‚é–“ã‚‚çŸ­ç¸®ã•ã‚Œã¦ã„ã¾ã™ï¼å­¦ç¿’ãŒã¨ã¦ã‚‚åŠ¹æœçš„ã«é€²ã‚“ã§ã„ã¾ã™ï¼")
                        elif slope_acc > 0.5:
                            st.success("ğŸ‘ æ­£ç­”ç‡ãŒä¸Šæ˜‡ã—ã¦ã„ã¾ã™ã€‚ç†è§£åº¦ãŒé«˜ã¾ã£ã¦ã„ã¾ã™ï¼")
                        elif slope_time < -0.2:
                            st.success("ğŸ‘ è§£ç­”æ™‚é–“ãŒçŸ­ç¸®ã•ã‚Œã¦ã„ã¾ã™ã€‚è§£ç­”ã‚¹ãƒ”ãƒ¼ãƒ‰ãŒå‘ä¸Šã—ã¦ã„ã¾ã™ï¼")
                        elif slope_acc < -0.5 and slope_time > 0.2:
                            st.error("ğŸ“ æ­£ç­”ç‡ãŒä¸‹é™ã—ã€è§£ç­”æ™‚é–“ã‚‚å¢—åŠ ã—ã¦ã„ã¾ã™ã€‚å­¦ç¿’æ–¹æ³•ã®è¦‹ç›´ã—ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚")
                        elif slope_acc < -0.5:
                            st.warning("ğŸ“ æ­£ç­”ç‡ãŒä¸‹é™ã—ã¦ã„ã¾ã™ã€‚åŸºç¤çš„ãªéƒ¨åˆ†ã®å¾©ç¿’ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
                        elif slope_time > 0.2:
                            st.warning("â° è§£ç­”æ™‚é–“ãŒå¢—åŠ ã—ã¦ã„ã¾ã™ã€‚å•é¡Œã®ç†è§£ã«æ™‚é–“ãŒã‹ã‹ã£ã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚")
                        else:
                            st.info("ğŸ“š å­¦ç¿’ã¯å®‰å®šã—ã¦é€²ã‚“ã§ã„ã¾ã™ã€‚ç¶™ç¶šçš„ãªå­¦ç¿’ã‚’ç¶šã‘ã¾ã—ã‚‡ã†ã€‚")
                    else:
                        # è§£ç­”æ™‚é–“ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„å ´åˆ
                        with col2:
                            st.info("â±ï¸ è§£ç­”æ™‚é–“ã®å‚¾å‘åˆ†æã«ã¯å°‘ãªãã¨ã‚‚3æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™")
                        
                        # æ­£ç­”ç‡ã®ã¿ã§è©•ä¾¡
                        if slope_acc > 0.5:
                            st.success("ğŸ‘ æ­£ç­”ç‡ãŒä¸Šæ˜‡ã—ã¦ã„ã¾ã™ã€‚ç†è§£åº¦ãŒé«˜ã¾ã£ã¦ã„ã¾ã™ï¼")
                        elif slope_acc < -0.5:
                            st.warning("ğŸ“ æ­£ç­”ç‡ãŒä¸‹é™ã—ã¦ã„ã¾ã™ã€‚åŸºç¤çš„ãªéƒ¨åˆ†ã®å¾©ç¿’ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
                        else:
                            st.info("ğŸ“š å­¦ç¿’ã¯å®‰å®šã—ã¦é€²ã‚“ã§ã„ã¾ã™ã€‚ç¶™ç¶šçš„ãªå­¦ç¿’ã‚’ç¶šã‘ã¾ã—ã‚‡ã†ã€‚")
                else:
                    # è§£ç­”æ™‚é–“ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆ
                    with col2:
                        st.info("â±ï¸ è§£ç­”æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                    
                    # æ­£ç­”ç‡ã®ã¿ã§è©•ä¾¡
                    if slope_acc > 0.5:
                        st.success("ğŸ‘ æ­£ç­”ç‡ãŒä¸Šæ˜‡ã—ã¦ã„ã¾ã™ã€‚ç†è§£åº¦ãŒé«˜ã¾ã£ã¦ã„ã¾ã™ï¼")
                    elif slope_acc < -0.5:
                        st.warning("ğŸ“ æ­£ç­”ç‡ãŒä¸‹é™ã—ã¦ã„ã¾ã™ã€‚åŸºç¤çš„ãªéƒ¨åˆ†ã®å¾©ç¿’ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
                    else:
                        st.info("ğŸ“š å­¦ç¿’ã¯å®‰å®šã—ã¦é€²ã‚“ã§ã„ã¾ã™ã€‚ç¶™ç¶šçš„ãªå­¦ç¿’ã‚’ç¶šã‘ã¾ã—ã‚‡ã†ã€‚")
                
                # è©³ç´°ãªåˆ†æçµæœ
                with st.expander("è©³ç´°ãªåˆ†æçµæœã‚’è¦‹ã‚‹"):
                    st.write(f"ç§»å‹•å¹³å‡ã®æ­£ç­”ç‡å¤‰åŒ–: {slope_acc:.2f}%/æ—¥")
                    
                    if has_time_data and len(recent_time_rolling_avg) >= 3:
                        st.write(f"ç§»å‹•å¹³å‡ã®è§£ç­”æ™‚é–“å¤‰åŒ–: {slope_time:.2f}åˆ†/æ—¥")
                        
                        # è§£ç­”æ™‚é–“ã®ãƒˆãƒ¬ãƒ³ãƒ‰è©•ä¾¡ã‚’è¿½åŠ 
                        if slope_time < -0.5:
                            st.success("è§£ç­”æ™‚é–“ã¯å¤§å¹…ã«çŸ­ç¸®ã•ã‚Œã¦ã„ã¾ã™ã€‚çŸ¥è­˜ã®å®šç€ãŒé€²ã‚“ã§ã„ã‚‹è¨¼æ‹ ã§ã™ï¼")
                        elif slope_time < -0.2:
                            st.success("è§£ç­”æ™‚é–“ã¯å¾ã€…ã«çŸ­ç¸®ã•ã‚Œã¦ã„ã¾ã™ã€‚å­¦ç¿’ã®æˆæœãŒå‡ºã¦ã„ã¾ã™ã€‚")
                        elif slope_time > 0.5:
                            st.warning("è§£ç­”æ™‚é–“ãŒå¤§å¹…ã«å¢—åŠ ã—ã¦ã„ã¾ã™ã€‚å•é¡Œã®é›£æ˜“åº¦ãŒä¸ŠãŒã£ãŸã‹ã€é›†ä¸­åŠ›ãŒä½ä¸‹ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                        elif slope_time > 0.2:
                            st.warning("è§£ç­”æ™‚é–“ãŒã‚„ã‚„å¢—åŠ ã—ã¦ã„ã¾ã™ã€‚å•é¡Œã‚’ã˜ã£ãã‚Šè€ƒãˆã‚‹ã‚ˆã†ã«ãªã£ãŸã‹ã€é›£æ˜“åº¦ãŒä¸ŠãŒã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                        else:
                            st.info("è§£ç­”æ™‚é–“ã¯å®‰å®šã—ã¦ã„ã¾ã™ã€‚ä¸€å®šã®ãƒšãƒ¼ã‚¹ã§è§£ç­”ã§ãã¦ã„ã¾ã™ã€‚")
                        
                        # æ­£ç­”ç‡ã¨è§£ç­”æ™‚é–“ã®ç›¸é–¢
                        if len(recent_rolling_avg) == len(recent_time_rolling_avg):
                            corr = pd.Series(recent_rolling_avg.values).corr(pd.Series(recent_time_rolling_avg.values))
                            st.write(f"æ­£ç­”ç‡ã¨è§£ç­”æ™‚é–“ã®ç›¸é–¢ä¿‚æ•°: {corr:.2f}")
                            
                            if corr < -0.5:
                                st.write("ğŸ‘‰ è§£ç­”æ™‚é–“ãŒçŸ­ããªã‚‹ã»ã©æ­£ç­”ç‡ãŒé«˜ããªã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚çŸ¥è­˜ãŒå®šç€ã—ã¦ãã¦ã„ã‚‹è¨¼æ‹ ã§ã™ï¼")
                            elif corr > 0.5:
                                st.write("ğŸ‘‰ è§£ç­”æ™‚é–“ã‚’ã‹ã‘ã‚‹ã»ã©æ­£ç­”ç‡ãŒé«˜ããªã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚ã˜ã£ãã‚Šè€ƒãˆã‚‹ã“ã¨ã§æ­£è§£ç‡ãŒä¸ŠãŒã£ã¦ã„ã¾ã™ã€‚")
        except Exception as e:
            st.error(f"ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            st.error(f"ã‚¨ãƒ©ãƒ¼ã®è©³ç´°: {type(e).__name__}")
        
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
else:
    st.info("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚") 