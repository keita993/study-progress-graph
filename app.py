import pandas as pd
import matplotlib
matplotlib.use('Agg')  # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’æ˜ç¤ºçš„ã«è¨­å®š

# ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’å¼·åŒ–
import matplotlib.font_manager as fm
import os

# ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’å¼·åŒ–ã™ã‚‹é–¢æ•°
def setup_japanese_font():
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚©ãƒ³ãƒˆã‚’æ¢ã™
    system_fonts = []
    
    # Windowsã®å ´åˆ
    if os.name == 'nt':
        font_paths = [
            r'C:\Windows\Fonts\meiryo.ttc',
            r'C:\Windows\Fonts\msgothic.ttc',
            r'C:\Windows\Fonts\YuGothM.ttc'
        ]
        for path in font_paths:
            if os.path.exists(path):
                system_fonts.append(path)
    
    # macOSã®å ´åˆ
    elif os.name == 'posix' and os.uname().sysname == 'Darwin':
        font_paths = [
            '/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ã‚·ãƒƒã‚¯ W3.ttc',
            '/System/Library/Fonts/AppleGothic.ttf',
            '/Library/Fonts/Osaka.ttf'
        ]
        for path in font_paths:
            if os.path.exists(path):
                system_fonts.append(path)
    
    # Linuxã®å ´åˆ
    elif os.name == 'posix':
        font_paths = [
            '/usr/share/fonts/truetype/fonts-japanese-gothic.ttf',
            '/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc'
        ]
        for path in font_paths:
            if os.path.exists(path):
                system_fonts.append(path)
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã¯è¨­å®š
    if system_fonts:
        for font_path in system_fonts:
            try:
                fm.fontManager.addfont(font_path)
                matplotlib.rcParams['font.family'] = fm.FontProperties(fname=font_path).get_name()
                return True
            except:
                continue
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
    matplotlib.rcParams['font.family'] = 'sans-serif'
    matplotlib.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans', 'Liberation Sans', 'Bitstream Vera Sans', 'sans-serif']
    
    return False

# ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’é©ç”¨
setup_japanese_font()

# ã‚°ãƒ©ãƒ•æç”»æ™‚ã®ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’å¼·åŒ–
def create_figure(figsize=(10, 6)):
    fig = plt.figure(figsize=figsize)
    ax = fig.add_subplot(111)
    
    # ã‚°ãƒ©ãƒ•å†…ã®ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
    plt.rcParams['axes.unicode_minus'] = False  # ãƒã‚¤ãƒŠã‚¹è¨˜å·ã‚’æ­£ã—ãè¡¨ç¤º
    plt.rcParams['font.size'] = 12  # ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚º
    
    return fig, ax

import matplotlib.pyplot as plt
import streamlit as st
import os
import urllib.request
import re

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="å¿œç”¨æƒ…å ±æŠ€è¡“è€…è©¦é¨“ å­¦ç¿’åˆ†æ",
    page_icon="ğŸ“Š"
)

st.title("å¿œç”¨æƒ…å ±æŠ€è¡“è€…è©¦é¨“ å­¦ç¿’åˆ†æ")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])

if uploaded_file is not None:
    try:
        # ãƒã‚¤ãƒŠãƒªãƒ¢ãƒ¼ãƒ‰ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        file_content = uploaded_file.read()
        
        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ¤œå‡º
        try:
            import chardet
            result = chardet.detect(file_content)
            detected_encoding = result['encoding']
            st.info(f"æ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {detected_encoding}")
        except:
            detected_encoding = None
        
        # æ§˜ã€…ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦ã™
        encodings_to_try = ['utf-8-sig', 'utf-8', 'shift-jis', 'cp932', 'euc-jp']
        if detected_encoding and detected_encoding not in encodings_to_try:
            encodings_to_try.insert(0, detected_encoding)
        
        df = None
        error_messages = []
        
        for encoding in encodings_to_try:
            try:
                # StringIOã‚’ä½¿ç”¨ã—ã¦ãƒ¡ãƒ¢ãƒªä¸Šã§ãƒ‡ã‚³ãƒ¼ãƒ‰
                import io
                string_data = io.StringIO(file_content.decode(encoding))
                df = pd.read_csv(string_data)
                st.success(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° '{encoding}' ã§æ­£å¸¸ã«èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                break
            except UnicodeDecodeError as e:
                error_messages.append(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° '{encoding}' ã§ã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—: {str(e)}")
                continue
            except Exception as e:
                error_messages.append(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° '{encoding}' ã§ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {str(e)}")
                continue
        
        if df is None:
            st.error("ã™ã¹ã¦ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            st.write("ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:")
            for msg in error_messages:
                st.write(f"- {msg}")
            
            # æœ€å¾Œã®æ‰‹æ®µ: ãƒã‚¤ãƒŠãƒªãƒ¢ãƒ¼ãƒ‰ã§ç›´æ¥èª­ã¿è¾¼ã¿
            try:
                import io
                uploaded_file.seek(0)
                df = pd.read_csv(uploaded_file, encoding='latin1', error_bad_lines=False)
                st.warning("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’'latin1'ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚æ–‡å­—åŒ–ã‘ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            except:
                st.stop()
        
        # ã‚«ãƒ©ãƒ åã‚’æ¤œå‡ºã—ã¦ä¿®æ­£ã™ã‚‹éƒ¨åˆ†ã‚’æ”¹å–„
        if df is not None:
            # æ–‡å­—åŒ–ã‘ã—ãŸã‚«ãƒ©ãƒ åã‚’ä¿®æ­£
            column_mapping = {}
            
            # ã‚«ãƒ©ãƒ ã®ä½ç½®ã«åŸºã¥ã„ã¦è‡ªå‹•æ¤œå‡º
            if len(df.columns) >= 6:
                # å…¸å‹çš„ãªCSVãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å ´åˆ
                column_positions = {
                    0: 'No.',
                    1: 'å­¦ç¿’æ—¥',
                    2: 'å‡ºé¡Œ',
                    3: 'åˆ†é‡',
                    4: 'è§£ç­”æ™‚é–“',
                    5: 'æ­£ç­”ç‡',
                    6: 'å›ç­”'
                }
                
                for i, col in enumerate(df.columns):
                    if i in column_positions:
                        column_mapping[col] = column_positions[i]
            
            # ä½ç½®ãƒ™ãƒ¼ã‚¹ã®ãƒãƒƒãƒ”ãƒ³ã‚°ãŒãªã„å ´åˆã¯å†…å®¹ãƒ™ãƒ¼ã‚¹ã§æ¤œå‡º
            if not column_mapping:
                for col in df.columns:
                    col_str = str(col)
                    col_bytes = col_str.encode('unicode_escape')
                    
                    # å­¦ç¿’æ—¥ã‚«ãƒ©ãƒ ã®æ¤œå‡º
                    if 'å­¦ç¿’' in col_str or 'æ—¥ä»˜' in col_str or 'æ—¥æ™‚' in col_str or (b'\\u' in col_bytes and (b'w' in col_bytes or b'K' in col_bytes)):
                        column_mapping[col] = 'å­¦ç¿’æ—¥'
                    # åˆ†é‡ã‚«ãƒ©ãƒ ã®æ¤œå‡º
                    elif 'åˆ†é‡' in col_str or 'ã‚«ãƒ†ã‚´ãƒª' in col_str or 'é …ç›®' in col_str or (len(col_str) <= 2 and b'\\u' in col_bytes):
                        column_mapping[col] = 'åˆ†é‡'
                    # æ­£ç­”ç‡ã‚«ãƒ©ãƒ ã®æ¤œå‡º
                    elif 'æ­£ç­”ç‡' in col_str or 'æ­£è§£ç‡' in col_str or 'å¾—ç‚¹ç‡' in col_str or any(c in col_str for c in ['ç‡', 'ï¼…', '%']):
                        column_mapping[col] = 'æ­£ç­”ç‡'
            
            # ã‚«ãƒ©ãƒ åã‚’ä¿®æ­£
            if column_mapping:
                df = df.rename(columns=column_mapping)
                st.success("ã‚«ãƒ©ãƒ åã‚’è‡ªå‹•æ¤œå‡ºã—ã¾ã—ãŸ")
        
        # å¿…è¦ãªã‚«ãƒ©ãƒ ã‚’ç‰¹å®š
        date_col = 'å­¦ç¿’æ—¥' if 'å­¦ç¿’æ—¥' in df.columns else None
        category_col = 'åˆ†é‡' if 'åˆ†é‡' in df.columns else None
        score_col = 'æ­£ç­”ç‡' if 'æ­£ç­”ç‡' in df.columns else None
        
        # ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ä½ç½®ã§æ¨æ¸¬
        if date_col is None and len(df.columns) > 1:
            date_col = df.columns[1]  # é€šå¸¸2åˆ—ç›®ãŒæ—¥ä»˜
        
        if category_col is None and len(df.columns) > 3:
            category_col = df.columns[3]  # é€šå¸¸4åˆ—ç›®ãŒåˆ†é‡
        
        if score_col is None and len(df.columns) > 5:
            score_col = df.columns[5]  # é€šå¸¸6åˆ—ç›®ãŒæ­£ç­”ç‡
        
        # ãã‚Œã§ã‚‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼
        if date_col is None or category_col is None or score_col is None:
            st.error("å¿…è¦ãªã‚«ãƒ©ãƒ ã‚’è‡ªå‹•æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        
        # æ—¥ä»˜ã‚’æ—¥ä»˜å‹ã«å¤‰æ›
        try:
            df[date_col] = pd.to_datetime(df[date_col])
        except:
            st.error(f"æ—¥ä»˜ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚«ãƒ©ãƒ  '{date_col}' ãŒæ—¥ä»˜å½¢å¼ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        
        # æ­£ç­”ç‡ã‚’æ•°å€¤å‹ã«å¤‰æ›
        try:
            # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆè¡¨è¨˜ï¼ˆä¾‹: 80%ï¼‰ã®å ´åˆ
            if df[score_col].dtype == 'object':
                df[score_col] = df[score_col].astype(str).str.rstrip('%').astype(float) / 100
            
            # ã™ã§ã«å°æ•°ç‚¹è¡¨è¨˜ï¼ˆä¾‹: 0.8ï¼‰ã®å ´åˆ
            if df[score_col].max() > 1:
                df[score_col] = df[score_col] / 100
        except:
            st.error(f"æ­£ç­”ç‡ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚«ãƒ©ãƒ  '{score_col}' ãŒæ•°å€¤ã¾ãŸã¯ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆå½¢å¼ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        
        # åˆ†æå‡¦ç†
        st.header("æ¦‚è¦")
        overall_avg = df[score_col].mean()
        st.metric("å…¨ä½“ã®å¹³å‡æ­£ç­”ç‡", f"{overall_avg*100:.1f}%")
        
        # æ—¥ä»˜ã”ã¨ã®å¹³å‡æ­£ç­”ç‡ã‚’è¨ˆç®—
        daily_avg = df.groupby(date_col)[score_col].mean() * 100
        
        # ç§»å‹•å¹³å‡ã‚’è¨ˆç®—ï¼ˆ7æ—¥é–“ï¼‰
        rolling_avg = daily_avg.rolling(window=7, min_periods=1).mean()
        
        # åˆ†é‡ã”ã¨ã®å¹³å‡æ­£ç­”ç‡ã‚’è¨ˆç®—
        category_avg = df.groupby(category_col)[score_col].mean() * 100
        
        # æ—¥ä»˜ã”ã¨ã®å¹³å‡æ­£ç­”ç‡ã‚°ãƒ©ãƒ•
        st.header("æ—¥ä»˜ã”ã¨ã®å¹³å‡æ­£ç­”ç‡")
        fig, ax = create_figure(figsize=(10, 6))
        ax.plot(daily_avg.index, daily_avg.values, label='æ—¥æ¬¡æ­£ç­”ç‡')
        ax.plot(rolling_avg.index, rolling_avg.values, label='7æ—¥ç§»å‹•å¹³å‡', linewidth=2)
        ax.set_ylabel('æ­£ç­”ç‡ (%)')
        ax.set_xlabel('å­¦ç¿’æ—¥')
        ax.legend()
        ax.grid(True, alpha=0.3)
        plt.tight_layout()  # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’èª¿æ•´
        st.pyplot(fig)
        
        # åˆ†é‡ã”ã¨ã®å¹³å‡æ­£ç­”ç‡ã‚°ãƒ©ãƒ•
        st.header("åˆ†é‡ã”ã¨ã®å¹³å‡æ­£ç­”ç‡")
        # Streamlitã®bar_chartã§ã¯ãªãã€matplotlibã‚’ä½¿ç”¨
        fig, ax = create_figure(figsize=(10, 6))
        category_avg_sorted = category_avg.sort_values(ascending=False)
        category_avg_sorted.plot(kind='bar', ax=ax)
        ax.set_ylabel('æ­£ç­”ç‡ (%)')
        ax.set_xlabel('åˆ†é‡')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()  # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’èª¿æ•´
        st.pyplot(fig)
        
        # åˆ†é‡ã”ã¨ã®å•é¡Œæ•°
        category_count = df.groupby(category_col).size().sort_values(ascending=False)
        
        # åˆ†é‡ã”ã¨ã®å•é¡Œæ•°ã¨æ­£ç­”ç‡è¡¨ç¤º
        st.header("åˆ†é‡ã”ã¨ã®å•é¡Œæ•°ã¨æ­£ç­”ç‡")
        category_stats = category_count.reset_index().rename(columns={category_col: 'åˆ†é‡', 0: 'å•é¡Œæ•°'})
        category_percent = category_avg_sorted.reset_index()
        category_percent['æ­£ç­”ç‡'] = category_percent[score_col].map('{:.1f}%'.format)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒãƒ¼ã‚¸
        category_stats_merged = pd.merge(
            category_stats, 
            category_percent[[category_col, 'æ­£ç­”ç‡']], 
            left_on='åˆ†é‡', 
            right_on=category_col,
            how='left'
        )
        
        if category_col != 'åˆ†é‡':
            category_stats_merged = category_stats_merged.drop(columns=[category_col])
        
        st.dataframe(category_stats_merged)
        
        # å­¦ç¿’ã®é€²æ—çŠ¶æ³
        st.header("å­¦ç¿’ã®é€²æ—çŠ¶æ³")
        total_questions = len(df)
        study_days = len(df[date_col].unique())
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ç·å•é¡Œæ•°", f"{total_questions}å•")
        with col2:
            st.metric("å­¦ç¿’æ—¥æ•°", f"{study_days}æ—¥")
        with col3:
            st.metric("1æ—¥å¹³å‡å•é¡Œæ•°", f"{total_questions/study_days:.1f}å•")
        
        # åˆ†é‡ã®æ–‡å­—åŒ–ã‘ã‚’ä¿®æ­£ã™ã‚‹éƒ¨åˆ†ã‚’è¿½åŠ 
        if category_col in df.columns:
            # åˆ†é‡åã«æ–‡å­—åŒ–ã‘ãŒã‚ã‚‹å ´åˆã¯ä¿®æ­£
            unique_categories = df[category_col].unique()
            category_mapping = {}
            
            for cat in unique_categories:
                cat_str = str(cat)
                # æ–‡å­—åŒ–ã‘ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹å ´åˆ
                if '\\u' in repr(cat_str) or len(cat_str) <= 2:
                    # æ—¢çŸ¥ã®åˆ†é‡åã¨ç…§åˆ
                    known_categories = {
                        'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£': ['ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£', 'ã‚»ã‚­ãƒ¥', 'ã‚»'],
                        'ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£': ['ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£', 'ã‚¢ãƒ¼ã‚­', 'ã‚¢'],
                        'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ': ['ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ', 'ãƒ—ãƒ­ãƒãƒ', 'ãƒ—'],
                        'ã‚µãƒ¼ãƒ“ã‚¹ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ': ['ã‚µãƒ¼ãƒ“ã‚¹ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ', 'ã‚µãƒ¼ãƒ“ã‚¹', 'ã‚µ'],
                        'ã‚·ã‚¹ãƒ†ãƒ æˆ¦ç•¥': ['ã‚·ã‚¹ãƒ†ãƒ æˆ¦ç•¥', 'æˆ¦ç•¥', 'æˆ¦'],
                        'çµŒå–¶æˆ¦ç•¥': ['çµŒå–¶æˆ¦ç•¥', 'çµŒå–¶', 'çµŒ'],
                        'ã‚·ã‚¹ãƒ†ãƒ é–‹ç™º': ['ã‚·ã‚¹ãƒ†ãƒ é–‹ç™º', 'é–‹ç™º', 'é–‹'],
                        'çµ„è¾¼ã‚·ã‚¹ãƒ†ãƒ é–‹ç™º': ['çµ„è¾¼ã‚·ã‚¹ãƒ†ãƒ é–‹ç™º', 'çµ„è¾¼', 'çµ„'],
                        'ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹': ['ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹', 'DB', 'ãƒ‡'],
                        'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯': ['ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯', 'NW', 'ãƒ'],
                        'ã‚·ã‚¹ãƒ†ãƒ ç›£æŸ»': ['ã‚·ã‚¹ãƒ†ãƒ ç›£æŸ»', 'ç›£æŸ»', 'ç›£']
                    }
                    
                    # æ–‡å­—åˆ—ã®é¡ä¼¼åº¦ã§æœ€ã‚‚è¿‘ã„åˆ†é‡ã‚’è¦‹ã¤ã‘ã‚‹
                    for known_cat, aliases in known_categories.items():
                        for alias in aliases:
                            if alias in cat_str or cat_str in alias:
                                category_mapping[cat] = known_cat
                                break
            
            # ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’é©ç”¨
            if category_mapping:
                df[category_col] = df[category_col].map(lambda x: category_mapping.get(x, x))
                st.success("åˆ†é‡åã®æ–‡å­—åŒ–ã‘ã‚’ä¿®æ­£ã—ã¾ã—ãŸ")
        
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
else:
    st.info("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚") 